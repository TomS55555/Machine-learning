{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfMXPXcsubsYDtMyBONEwk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TomS55555/Machine-learning/blob/main/Decision_trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine learning & Inductive inference\n",
        "\n",
        "## Chapter 2: Decision trees\n",
        "\n",
        "### What are they? \n",
        "Classification and regression trees (CART) are defined by recursively partitioning the input space, and defining a local model in each resulting region of the input space. The model can be represented by a tree, with one leaf per region.  \n",
        "The tree consists of a set of nested decision rules. At each node $i$, a specific feature dimension $d_i$ of the input vector $\\mathbf{x}$ is compared to a threshold value $t_i$ and the input is then passed down to the left or to the right branch, depending on whether it is above or below the threshold.  \n",
        "A regression tree on a dataset $\\mathcal{D}=\\{\\mathbf{x}_i,y_i\\}_{i=1}^N$ can then be defined as \n",
        "\\begin{equation}\n",
        "f(\\mathbf{x}; ùõâ ) = \\sum_{j=1}^J w_j \\mathbb{I}(\\mathbf{x}\\in R_j)\n",
        "\\end{equation} \n",
        "where $J$ is the amount of leaf nodes and each $w_j$ is the average value of all examples classified in region $R_j$ such that $ùõâ=\\{(R_j,w_j):j=1:J\\}$ and $$w_j = \\frac{\\sum_{n=1}^Ny_n\\mathbb{I}(\\mathbf{x}\\in R_j)}{\\sum_{n=1}^N\\mathbb{I}(\\mathbf{x}\\in R_j)}$$  \n",
        "For classification problems, the leaves contain distributions over the labels, rather than just the mean response.  \n",
        "### How to fit them?\n",
        "To fit the model, a loss function needs to be defined:\n",
        "\\begin{equation}\n",
        "\\mathcal{L}(ùõâ) = \\sum_{n=1}^N\\ell(y_n, f(\\mathbf{x}_n,ùõâ)) = \\sum_{j=1}^J\\sum_{\\mathbf{x}_n\\in R_j} \\ell(y_i,w_j)\n",
        "\\end{equation}\n",
        "This loss is not differentiable because the discrete tree structure needs to be learned."
      ],
      "metadata": {
        "id": "mWygzWDz0uHV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I2XtMP4C4Txs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}